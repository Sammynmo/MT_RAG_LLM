{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***MongoDB Schema Vector Set up***\n",
    "\n",
    "link: https://cloud.mongodb.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading packages, libraries and secrets into notebook**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Setup.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In Google Colab, the Google Drive can be mounted as follows to access documents\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Path: DB_schema_testing.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2ee614bfaa0464b985f6eb3cf53568e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Column_name  Table_name DB_name            Lookup_name\n",
      "0       CONTID  CONTINENTS   car_1      CONTID CONTINENTS\n",
      "1    CONTINENT  CONTINENTS   car_1   CONTINENT CONTINENTS\n",
      "2    COUNTRYID   COUNTRIES   car_1    COUNTRYID COUNTRIES\n",
      "3  COUNTRYNAME   COUNTRIES   car_1  COUNTRYNAME COUNTRIES\n",
      "4    CONTINENT   COUNTRIES   car_1    CONTINENT COUNTRIES\n"
     ]
    }
   ],
   "source": [
    "# Upload the dataset and transform to dataframe\n",
    "# Define the dataset path\n",
    "dataset_path = \"DB_schema_testing.csv\"\n",
    "print(\"Dataset Path:\", dataset_path)\n",
    "\n",
    "# Check if the file exists at the specified path\n",
    "if not os.path.isfile(dataset_path):\n",
    "    raise FileNotFoundError(f\"Unable to find the file at {dataset_path}\")\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset('csv', data_files=dataset_path)\n",
    "\n",
    "# Convert the dataset to a pandas dataframe\n",
    "dataset_df = pd.DataFrame(dataset[\"train\"])\n",
    "\n",
    "# Print a few rows to verify\n",
    "print(dataset_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the embedding model and getting the embeddings for the dataframe\n",
    "embedding_model = SentenceTransformer(\"thenlper/gte-large\")\n",
    "def get_embedding(text: str) -> list[float]:\n",
    "    if not text.strip():\n",
    "        print(\"Attempted to get embedding for empty text.\")\n",
    "        return []\n",
    "\n",
    "    embedding = embedding_model.encode(text)\n",
    "\n",
    "    return embedding.tolist()\n",
    "dataset_df[\"embedding\"] = dataset_df[\"Lookup_name\"].apply(get_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pinged your deployment. You successfully connected to MongoDB!\n"
     ]
    }
   ],
   "source": [
    "# MongoDB setup\n",
    "client = MongoClient(MONGO_URI_Schema_All)\n",
    "dbName = \"MVector\"\n",
    "collectionName = \"MTSchemaAll\"\n",
    "collection = client[dbName][collectionName]\n",
    "index_name = \"vector_index_schema_all\"\n",
    "\n",
    "# Send a ping to confirm a successful connection\n",
    "try:\n",
    "    client.admin.command('ping')\n",
    "    print(\"Pinged your deployment. You successfully connected to MongoDB!\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeleteResult({'n': 0, 'electionId': ObjectId('7fffffff00000000000000b4'), 'opTime': {'ts': Timestamp(1726496420, 25), 't': 180}, 'ok': 1.0, '$clusterTime': {'clusterTime': Timestamp(1726496420, 25), 'signature': {'hash': b'\\xc1\\xca\\x10\\x9ck\\x87\\xd4\\x82@g\\xda`i\\xe5\\x16\\xe6\\xe05\\xff\\xe2', 'keyId': 7351804200415657986}}, 'operationTime': Timestamp(1726496420, 25)}, acknowledged=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete any existing records in the collection before loading the new data\n",
    "collection.delete_many({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data ingestion into MongoDB completed\n"
     ]
    }
   ],
   "source": [
    "# Insert the documents into the collection\n",
    "documents = dataset_df.to_dict(\"records\")\n",
    "collection.insert_many(documents)\n",
    "print(\"Data ingestion into MongoDB completed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mtenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
