{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***MongoDB Schema Vector Set up***\n",
    "\n",
    "link: https://cloud.mongodb.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading packages, libraries and secrets into notebook**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\samir\\Documents\\GitHub\\MT_RAG_LLM\\mtgitenv\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\samir\\Documents\\GitHub\\MT_RAG_LLM\\mtgitenv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importing the required libraries\n",
    "from pymongo import MongoClient\n",
    "from sentence_transformers import SentenceTransformer # https://huggingface.co/thenlper/gte-large\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from pymongo.mongo_client import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing the secrets from the environment variables\n",
    "load_dotenv()\n",
    "MONGO_URI_schema = os.getenv(\"MONGO_URI_Schema\")\n",
    "HF_Token = os.getenv(\"HF_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Path: DB_schema_testing.csv\n",
      "   Column_name  Table_name DB_name                  Lookup_name\n",
      "0       CONTID  CONTINENTS   car_1      car_1 CONTINENTS CONTID\n",
      "1    CONTINENT  CONTINENTS   car_1   car_1 CONTINENTS CONTINENT\n",
      "2    COUNTRYID   COUNTRIES   car_1    car_1 COUNTRIES COUNTRYID\n",
      "3  COUNTRYNAME   COUNTRIES   car_1  car_1 COUNTRIES COUNTRYNAME\n",
      "4    CONTINENT   COUNTRIES   car_1    car_1 COUNTRIES CONTINENT\n"
     ]
    }
   ],
   "source": [
    "# Upload the dataset and transform to dataframe\n",
    "# Define the dataset path\n",
    "dataset_path = \"DB_schema_testing.csv\"\n",
    "print(\"Dataset Path:\", dataset_path)\n",
    "\n",
    "# Check if the file exists at the specified path\n",
    "if not os.path.isfile(dataset_path):\n",
    "    raise FileNotFoundError(f\"Unable to find the file at {dataset_path}\")\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset('csv', data_files=dataset_path)\n",
    "\n",
    "# Convert the dataset to a pandas dataframe\n",
    "dataset_df = pd.DataFrame(dataset[\"train\"])\n",
    "\n",
    "# Print a few rows to verify\n",
    "print(dataset_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the embedding model and getting the embeddings for the dataframe\n",
    "embedding_model = SentenceTransformer(\"thenlper/gte-large\")\n",
    "def get_embedding(text: str) -> list[float]:\n",
    "    if not text.strip():\n",
    "        print(\"Attempted to get embedding for empty text.\")\n",
    "        return []\n",
    "\n",
    "    embedding = embedding_model.encode(text)\n",
    "\n",
    "    return embedding.tolist()\n",
    "dataset_df[\"embedding\"] = dataset_df[\"Lookup_name\"].apply(get_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pinged your deployment. You successfully connected to MongoDB!\n"
     ]
    }
   ],
   "source": [
    "# MongoDB setup\n",
    "client = MongoClient(MONGO_URI_schema)\n",
    "dbName = \"MVector\"\n",
    "collectionName = \"MTSchemaAll\"\n",
    "collection = client[dbName][collectionName]\n",
    "index_name = \"vector_index_schema_all\"\n",
    "\n",
    "# Send a ping to confirm a successful connection\n",
    "try:\n",
    "    client.admin.command('ping')\n",
    "    print(\"Pinged your deployment. You successfully connected to MongoDB!\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeleteResult({'n': 488, 'electionId': ObjectId('7fffffff00000000000000b7'), 'opTime': {'ts': Timestamp(1727437251, 492), 't': 183}, 'ok': 1.0, '$clusterTime': {'clusterTime': Timestamp(1727437251, 499), 'signature': {'hash': b'\\xd8q\\\\L\\xb8\\x15^.\\xbc\\xa7\\x89\\xe0\\xb9\\xab`\\xb5\\x0e\\x81/^', 'keyId': 7385925018342916097}}, 'operationTime': Timestamp(1727437251, 492)}, acknowledged=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete any existing records in the collection before loading the new data\n",
    "collection.delete_many({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data ingestion into MongoDB completed\n"
     ]
    }
   ],
   "source": [
    "# Insert the documents into the collection\n",
    "documents = dataset_df.to_dict(\"records\")\n",
    "collection.insert_many(documents)\n",
    "print(\"Data ingestion into MongoDB completed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mtenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
