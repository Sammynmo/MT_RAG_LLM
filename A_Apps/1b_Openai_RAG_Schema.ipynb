{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***OPENAI RAG LLM setup***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading packages, libraries and secrets into notebook**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samira/Documents/GitHub/MT_RAG_LLM/mtgitenv/lib/python3.12/site-packages/langchain_mongodb/utils.py:70: SyntaxWarning: invalid escape sequence '\\ '\n",
      "  \"\"\"Compute Maximal Marginal Relevance (MMR).\n"
     ]
    }
   ],
   "source": [
    "# Importing the required libraries\n",
    "from pymongo import MongoClient\n",
    "from langchain_mongodb import MongoDBAtlasVectorSearch\n",
    "from langchain_openai import OpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "import gradio as gr\n",
    "from gradio.themes.base import Base\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "from sentence_transformers import SentenceTransformer # https://huggingface.co/thenlper/gte-large\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing the secrets from the environment variables\n",
    "load_dotenv()\n",
    "MONGO_URI_SQL = os.getenv(\"MONGO_URI_SQL\")\n",
    "MONGO_URI_schema = os.getenv(\"MONGO_URI_Schema\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "HF_Token = os.getenv(\"HF_TOKEN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Generating the embedding***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding model setup\n",
    "embedding_model = SentenceTransformer(\"thenlper/gte-large\")\n",
    "\n",
    "class CustomEmbeddingFunction:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def embed_documents(self, texts):\n",
    "        \"\"\"Embeds a list of documents.\"\"\"\n",
    "        embeddings = self.model.encode(texts)\n",
    "        return embeddings.tolist()\n",
    "\n",
    "    def embed_query(self, text):\n",
    "        \"\"\"Embeds a single query.\"\"\"\n",
    "        embedding = self.model.encode(text)\n",
    "        return embedding.tolist()\n",
    "\n",
    "# Wrap the SentenceTransformer model\n",
    "embedding_function = CustomEmbeddingFunction(embedding_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*MongoDB Vector Setup*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SQL Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_SQL = MongoClient(MONGO_URI_SQL)\n",
    "dbName_SQL = \"MVector\"\n",
    "collectionName_SQL = \"MTSQL\"\n",
    "collection_SQL = client_SQL[dbName_SQL][collectionName_SQL]\n",
    "index_name_SQL = \"vector_index_SQL\"\n",
    "\n",
    "# Vector store setup\n",
    "vector_store_SQL = MongoDBAtlasVectorSearch(\n",
    "    client=client_SQL,\n",
    "    database=dbName_SQL,\n",
    "    collection=collection_SQL,\n",
    "    index_name=index_name_SQL,\n",
    "    embedding=embedding_function,\n",
    "    text_key=\"Query\"  \n",
    ")\n",
    "\n",
    "# Retriever setup\n",
    "retriever_SQL = vector_store_SQL.as_retriever(search_kwargs={\"k\": 4})\n",
    "\n",
    "# Define a custom logging retriever to see what the retriever is passing on\n",
    "class LoggingRetrieverSQL:\n",
    "    def __init__(self, retriever_SQL):\n",
    "        self.retriever_SQL = retriever_SQL\n",
    "\n",
    "    def __call__(self, query):\n",
    "        # Retrieve the documents\n",
    "        documents_SQL = self.retriever_SQL.invoke(query)\n",
    "        \n",
    "        # Log or print the retrieved documents\n",
    "        print(\"Retrieved Documents:\")\n",
    "        for doc in documents_SQL:\n",
    "            print(doc)\n",
    "        \n",
    "        # Return the retrieved documents\n",
    "        return documents_SQL\n",
    "\n",
    "# Wrap your retriever with the logging retriever\n",
    "logging_retriever_SQL = LoggingRetrieverSQL(retriever_SQL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schema Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_schema = MongoClient(MONGO_URI_schema)\n",
    "dbName_schema = \"MVector\"\n",
    "collectionName_schema = \"MTSchemaAll\"\n",
    "collection_schema = client_schema[dbName_schema][collectionName_schema]\n",
    "index_name_schema = \"vector_index_schema_all\"\n",
    "\n",
    "## Schema Vector setup\n",
    "# Vector store setup\n",
    "vector_store_schema = MongoDBAtlasVectorSearch(\n",
    "    client=client_schema,\n",
    "    database=dbName_schema,\n",
    "    collection=collection_schema,\n",
    "    index_name=index_name_schema,\n",
    "    embedding=embedding_function,\n",
    "    text_key=\"Lookup_name\"  \n",
    ")\n",
    "\n",
    "\n",
    "# Retriever setup\n",
    "retriever_schema = vector_store_schema.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "# Define a custom logging retriever to see what the retriever is passing on\n",
    "class LoggingRetrieverSchema:\n",
    "    def __init__(self, retriever_schema):\n",
    "        self.retriever_schema = retriever_schema\n",
    "\n",
    "    def __call__(self, input_value):\n",
    "        # Retrieve the documents\n",
    "        documents_schema = self.retriever_schema.invoke(input_value)\n",
    "        \n",
    "        # Log or print the retrieved documents\n",
    "        print(\"Retrieved Schema:\")\n",
    "        for doc in documents_schema:\n",
    "            print(doc)\n",
    "        \n",
    "        # Return the retrieved documents\n",
    "        return documents_schema\n",
    "\n",
    "# Wrap your retriever with the logging retriever\n",
    "logging_retriever_schema = LoggingRetrieverSchema(retriever_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Chain setup***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved Schema:\n",
      "page_content='cre_Doc_Template_Mgt DOCUMENTS DOCUMENT_DESCRIPTION' metadata={'_id': '66f699c316868673a7a59ee7', 'Column_name': 'DOCUMENT_DESCRIPTION', 'Table_name': 'DOCUMENTS', 'DB_name': 'cre_Doc_Template_Mgt'}\n",
      "page_content='cre_Doc_Template_Mgt DOCUMENTS OTHER_DETAILS' metadata={'_id': '66f699c316868673a7a59ee8', 'Column_name': 'OTHER_DETAILS', 'Table_name': 'DOCUMENTS', 'DB_name': 'cre_Doc_Template_Mgt'}\n",
      "page_content='cre_Doc_Template_Mgt PARAGRAPHS OTHER_DETAILS' metadata={'_id': '66f699c316868673a7a59eec', 'Column_name': 'OTHER_DETAILS', 'Table_name': 'PARAGRAPHS', 'DB_name': 'cre_Doc_Template_Mgt'}\n",
      "page_content='real_estate_properties PROPERTIES  HSE_FEATURE_2' metadata={'_id': '66f699c316868673a7a59ff4', 'Column_name': 'HSE_FEATURE_2', 'Table_name': 'PROPERTIES ', 'DB_name': 'real_estate_properties'}\n",
      "page_content='real_estate_properties PROPERTIES  HSE_FEATURE_3' metadata={'_id': '66f699c316868673a7a59ff5', 'Column_name': 'HSE_FEATURE_3', 'Table_name': 'PROPERTIES ', 'DB_name': 'real_estate_properties'}\n",
      "Retrieved Documents:\n",
      "page_content='SELECT city FROM business WHERE name  =  \"Taj Mahal\";' metadata={'_id': '66cf12c13c2173e47d7b0793', 'Question': 'Find all cities which has a \" Taj Mahal \" .'}\n",
      "page_content='SELECT homepage FROM organization WHERE name  =  \"University of Michigan\";' metadata={'_id': '66cf12c13c2173e47d7b0806', 'Question': 'return me the homepage of \" University of Michigan \" .'}\n",
      "page_content='SELECT state FROM business WHERE name  =  \"Whataburger\";' metadata={'_id': '66cf12c13c2173e47d7b0790', 'Question': 'Find all states in which there is a Whataburger'}\n",
      "page_content='SELECT name FROM business WHERE rating  >  4.5;' metadata={'_id': '66cf12c13c2173e47d7b078d', 'Question': 'List all the businesses with more than 4.5 stars'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'**Translation:**\\n\"Select the city from the business table where the name is \\'Taj Mahal\\'.\"\\n\\n**Explanation of the SQL Query:**\\n1. **SELECT city**: This part of the query specifies that we want to retrieve the \\'city\\' column from the results.\\n2. **FROM business**: This indicates that we are looking for the data in the \\'business\\' table.\\n3. **WHERE name = \"Taj Mahal\"**: This condition filters the results to only include rows where the \\'name\\' column matches \"Taj Mahal\".\\n\\nIn summary, the query is designed to find and list all cities that have a business named \"Taj Mahal\".'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\n",
    "\n",
    "output_length = len(query.split())*3 # word count of SQL query multiplied by four\n",
    "\n",
    "DB_name = \"\"\n",
    "\n",
    "input_value = DB_name + query\n",
    "\n",
    "# Model and parsing setup\n",
    "model = ChatOpenAI(api_key=OPENAI_API_KEY, model=\"gpt-4o-mini\", temperature=0)\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# Define prompt template\n",
    "template = \"\"\"\n",
    "Provide first a natural language Translation followed by an Explanation of the SQL Query. Go through it step by step and output the result in simple and concise language. Use the information of the Context as examples for the translation and the schema to get the names of tables and columns. Keep the output in line with the Length number.\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Schema: {schema}\n",
    "\n",
    "Query: {query}\n",
    "\n",
    "Input-value : {input_value}\n",
    "\n",
    "Length: {output_length}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# Chain setup\n",
    "chain_1b = (\n",
    "    {\"context\": logging_retriever_SQL, \"schema\": logging_retriever_schema, \"query\": RunnablePassthrough(), \"input_value\": RunnablePassthrough(), \"output_length\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | parser\n",
    ")\n",
    "\n",
    "# Execute the chain with the logging retriever\n",
    "chain_1b.invoke(input_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Chat interface setup***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Markdown format of Chat interface setup for testing.\n",
    "\n",
    "Change cell type below to Python, when running only this script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the chain_invoke function\n",
    "def chain_1b_invoke(query, DB_name):\n",
    "    input_value = query if not DB_name else DB_name + query\n",
    "    # Execute the chain with the logging retriever\n",
    "    result = chain_1b.invoke(input_value)\n",
    "    # Return the result \n",
    "    return result\n",
    "\n",
    "# Create a web interface for the app, using Gradio\n",
    "with gr.Blocks(theme=Base(), title=\"Question Answering App using Vector Search + RAG\") as demo:\n",
    "    gr.Markdown(\n",
    "        \"\"\"\n",
    "        # Question Answering App using Atlas Vector Search + RAG Architecture\n",
    "        \"\"\")\n",
    "    query = gr.Textbox(label=\"Enter your SQL statement:\")\n",
    "    DB_name = gr.Textbox(label=\"Enter the database name: (Optional)\")\n",
    "    with gr.Row():\n",
    "        button = gr.Button(\"Submit\", variant=\"primary\")\n",
    "    output = gr.Textbox(lines=1, max_lines=30, label=\"Natural language translation and explanation:\")\n",
    "\n",
    "# Call chain_invoke function upon clicking the Submit button\n",
    "    button.click(chain_1b_invoke, inputs=[query, DB_name], outputs=output)\n",
    "\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mtgitenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
