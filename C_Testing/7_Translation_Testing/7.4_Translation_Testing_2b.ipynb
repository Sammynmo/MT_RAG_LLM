{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Translation Testing of 2b OpenAI with RAG SQL**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading packages, libraries and secrets into notebook**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.util import cos_sim\n",
    "from sentence_transformers.quantization import quantize_embeddings\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing the secrets from the environment variables\n",
    "load_dotenv()\n",
    "HF_Token = os.getenv(\"HF_TOKEN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading data into dataframe for testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the dataset and transform to dataframe\n",
    "# Define the dataset path\n",
    "dataset_path = \"../8_Testing_Input_and_Output/App_Output_2b.csv\"\n",
    "print(\"Dataset Path:\", dataset_path)\n",
    "\n",
    "# Check if the file exists at the specified path\n",
    "if not os.path.isfile(dataset_path):\n",
    "    raise FileNotFoundError(f\"Unable to find the file at {dataset_path}\")\n",
    "\n",
    "# Load the dataset\n",
    "testing_output_2b = load_dataset('csv', data_files=dataset_path)\n",
    "\n",
    "# Convert the dataset to a pandas dataframe\n",
    "df_2b_testing_output = testing_output_2b['train'].to_pandas()\n",
    "\n",
    "# Print a few rows to verify\n",
    "print(df_2b_testing_output.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Semantic Translation Testing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Embedding 1*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pre-trained model for generating sentence embeddings\n",
    "embedding_model_1 = AutoModel.from_pretrained('jinaai/jina-embeddings-v3', trust_remote_code=True) # https://huggingface.co/jinaai/jina-embeddings-v3\n",
    "\n",
    "# Function to compute embeddings and similarity\n",
    "def Translation_assessment_1(df_2b_testing_output):\n",
    "    df_2b_testing_output['Question'] = df_2b_testing_output['Question'].fillna('').astype(str)\n",
    "    df_2b_testing_output['Translation'] = df_2b_testing_output['Translation'].fillna('').astype(str)\n",
    "    \n",
    "    # Generate embeddings for the \"Question\" and \"Translation\" columns\n",
    "    question_embeddings = embedding_model_1.encode(df_2b_testing_output['Question'].tolist(), task=\"text-matching\", convert_to_tensor=True)\n",
    "    translation_embeddings = embedding_model_1.encode(df_2b_testing_output['Translation'].tolist(), task=\"text-matching\", convert_to_tensor=True)\n",
    "\n",
    "    # Calculate cosine similarity for each row\n",
    "    similarities = cosine_similarity(question_embeddings, translation_embeddings)\n",
    "\n",
    "    # Since cosine_similarity returns a matrix, we extract the diagonal (row-wise comparison)\n",
    "    df_2b_testing_output['Similarity_1'] = np.diagonal(similarities)\n",
    "\n",
    "    return df_2b_testing_output\n",
    "\n",
    "# Call the function and process the dataframe\n",
    "df_translation_assessment_1 = Translation_assessment_1(df_2b_testing_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Embedding 2*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Specify preferred dimensions\n",
    "dimensions = 512\n",
    "\n",
    "# 2. Load the model\n",
    "embedding_model_2 = SentenceTransformer(\"mixedbread-ai/mxbai-embed-large-v1\", truncate_dim=dimensions)  # https://huggingface.co/mixedbread-ai/mxbai-embed-large-v1\n",
    "\n",
    "# Function to generate a detailed instruction for the query\n",
    "def get_detailed_instruct(task_description: str, query: str) -> str:\n",
    "    return f'Instruct: {task_description}\\nQuery: {query}'\n",
    "\n",
    "# Function to compute embeddings and similarity\n",
    "def Translation_assessment_2(df_2b_testing_output):\n",
    "    # Define task instruction for the queries\n",
    "    task = 'Compare the question and translation to assess the quality of the translation.'\n",
    "\n",
    "    # Add instruction to the \"Question\" column\n",
    "    questions_with_instructions = [\n",
    "        get_detailed_instruct(task, question) for question in df_2b_testing_output['Question'].tolist()\n",
    "    ]\n",
    "\n",
    "    # Generate a list of documents to encode\n",
    "    docs = questions_with_instructions + df_2b_testing_output['Translation'].tolist()\n",
    "    \n",
    "    # 2. Encode\n",
    "    embeddings = embedding_model_2.encode(docs)\n",
    "\n",
    "    # Optional: Quantize the embeddings\n",
    "    binary_embeddings = quantize_embeddings(embeddings, precision=\"ubinary\")\n",
    "\n",
    "    # Calculate cosine similarity between the first half (questions) and the second half (translations)\n",
    "    question_embeddings = embeddings[:len(questions_with_instructions)]\n",
    "    translation_embeddings = embeddings[len(questions_with_instructions):]\n",
    "\n",
    "    # Calculate cosine similarity\n",
    "    similarities = cos_sim(question_embeddings, translation_embeddings)\n",
    "\n",
    "    # Since cos_sim returns a matrix, we extract the diagonal (row-wise comparison)\n",
    "    df_2b_testing_output['Similarity_V2'] = np.diagonal(similarities.cpu().numpy())\n",
    "\n",
    "    return df_2b_testing_output\n",
    "\n",
    "# Call the function and process the dataframe\n",
    "df_translation_assessment_2 = Translation_assessment_2(df_2b_testing_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Embedding 3*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pre-trained model for generating sentence embeddings\n",
    "embedding_model = SentenceTransformer(\"thenlper/gte-large\")\n",
    "\n",
    "# Function to compute embeddings and similarity\n",
    "def Translation_assessment_3(df_2b_testing_output):\n",
    "    # Generate embeddings for the \"Question\" and \"Translation\" columns\n",
    "    question_embeddings = embedding_model.encode(df_2b_testing_output['Question'].tolist(), convert_to_tensor=True).cpu()\n",
    "    translation_embeddings = embedding_model.encode(df_2b_testing_output['Translation'].tolist(), convert_to_tensor=True).cpu()\n",
    "\n",
    "    # Calculate cosine similarity for each row\n",
    "    similarities = cosine_similarity(question_embeddings, translation_embeddings)\n",
    "\n",
    "    # Since cosine_similarity returns a matrix, we extract the diagonal (row-wise comparison)\n",
    "    df_2b_testing_output['Similarity_V3'] = np.diagonal(similarities)\n",
    "\n",
    "    return df_2b_testing_output\n",
    "\n",
    "# Call the function and process the dataframe\n",
    "df_translation_assessment_3 = Translation_assessment_3(df_2b_testing_output)\n",
    "\n",
    "# Saving to CSV with the similarity score\n",
    "df_translation_assessment_3.to_csv('../8_Testing_Input_and_Output/Translation_assessment_2b.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mtgitenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
