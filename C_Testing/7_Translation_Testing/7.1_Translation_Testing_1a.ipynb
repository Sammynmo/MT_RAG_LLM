{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\samir\\Documents\\GitHub\\MT_RAG_LLM\\mtgitenv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importing the required libraries\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.util import cos_sim\n",
    "from sentence_transformers.quantization import quantize_embeddings\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing the secrets from the environment variables\n",
    "load_dotenv()\n",
    "HF_Token = os.getenv(\"HF_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Path: ../8_Testing_Input_and_Output/App_Output_1a.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e7c08c874034a8192afaad6a0a8c294",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            DB_ID                                              Query  \\\n",
      "0  concert_singer  SELECT T2.name ,  T2.capacity FROM concert AS ...   \n",
      "1          pets_1  SELECT T1.fname ,  T1.age FROM student AS T1 J...   \n",
      "2           car_1  SELECT T1.CountryName FROM COUNTRIES AS T1 JOI...   \n",
      "3           car_1  SELECT T2.MakeId ,  T2.Make FROM CARS_DATA AS ...   \n",
      "4           car_1  select t1.id ,  t1.maker from car_makers as t1...   \n",
      "\n",
      "                                            Question  \\\n",
      "0  Show the stadium name and capacity with most n...   \n",
      "1  Find the first name and age of students who ha...   \n",
      "2  Which countries in europe have at least 3 car ...   \n",
      "3  Among the cars with more than lowest horsepowe...   \n",
      "4  Which are the car makers which produce at leas...   \n",
      "\n",
      "                                              Output  \\\n",
      "0  The query aims to find the name of the stadium...   \n",
      "1  The query aims to find the first name and age ...   \n",
      "2  The query aims to identify the countries that ...   \n",
      "3  The query aims to find the project that requir...   \n",
      "4  Sure, here is the translation and explanation ...   \n",
      "\n",
      "                                         Translation  \\\n",
      "0  The query wants to find the name of the stadiu...   \n",
      "1  The query aims to find the first name and age ...   \n",
      "2  The query aims to identify the countries that ...   \n",
      "3  The query aims to find the project that requir...   \n",
      "4  The query aims to identify assets that have tw...   \n",
      "\n",
      "                                         Explanation  \n",
      "0  The query aims to find the name of the stadium...  \n",
      "1  1. **Selecting Columns:**\\n   - The query sele...  \n",
      "2  1. **Selecting T1.CountryName:** The query sel...  \n",
      "3  The query is composed of several parts:\\n\\n- *...  \n",
      "4  The query is composed of several clauses and j...  \n"
     ]
    }
   ],
   "source": [
    "# Upload the dataset and transform to dataframe\n",
    "# Define the dataset path\n",
    "dataset_path = \"../8_Testing_Input_and_Output/App_Output_1a.csv\"\n",
    "print(\"Dataset Path:\", dataset_path)\n",
    "\n",
    "# Check if the file exists at the specified path\n",
    "if not os.path.isfile(dataset_path):\n",
    "    raise FileNotFoundError(f\"Unable to find the file at {dataset_path}\")\n",
    "\n",
    "# Load the dataset\n",
    "testing_output_1a = load_dataset('csv', data_files=dataset_path)\n",
    "\n",
    "# Convert the dataset to a pandas dataframe\n",
    "df_1a_testing_output = testing_output_1a['train'].to_pandas()\n",
    "\n",
    "# Print a few rows to verify\n",
    "print(df_1a_testing_output.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Version 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7d67d3d3bd9445b8d18516ed7d764e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration_xlm_roberta.py:   0%|          | 0.00/6.54k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\samir\\Documents\\GitHub\\MT_RAG_LLM\\mtgitenv\\Lib\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\samir\\.cache\\huggingface\\hub\\models--jinaai--xlm-roberta-flash-implementation. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n",
      "- configuration_xlm_roberta.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1195873115614e808297947cdb56302d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_lora.py:   0%|          | 0.00/15.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a241db2cc0e4d1895f2a4a5df184ef7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mha.py:   0%|          | 0.00/34.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a5c22540b054cf0b304cb0362a4895f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "rotary.py:   0%|          | 0.00/24.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n",
      "- rotary.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n",
      "- mha.py\n",
      "- rotary.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adf9761c80d8421d994f2351c89fdd51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "xlm_padding.py:   0%|          | 0.00/10.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n",
      "- xlm_padding.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86da284a447b40a88c15081dbabc1dca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_xlm_roberta.py:   0%|          | 0.00/50.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0534dee4035f4578b936c2061a4c626b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mlp.py:   0%|          | 0.00/7.62k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n",
      "- mlp.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "693f0928a6994401b64b52d7e0d4da7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding.py:   0%|          | 0.00/3.88k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n",
      "- embedding.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25681567c7e14bf1a0b8b0cdf51566ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "block.py:   0%|          | 0.00/17.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17d11a38c885451f9a6608fcfc5a3942",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "stochastic_depth.py:   0%|          | 0.00/3.76k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n",
      "- stochastic_depth.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n",
      "- block.py\n",
      "- stochastic_depth.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n",
      "- modeling_xlm_roberta.py\n",
      "- mlp.py\n",
      "- embedding.py\n",
      "- block.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n",
      "- modeling_lora.py\n",
      "- mha.py\n",
      "- xlm_padding.py\n",
      "- modeling_xlm_roberta.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    }
   ],
   "source": [
    "# Load a pre-trained model for generating sentence embeddings\n",
    "embedding_model_1 = AutoModel.from_pretrained('jinaai/jina-embeddings-v3', trust_remote_code=True) # https://huggingface.co/jinaai/jina-embeddings-v3\n",
    "\n",
    "# Function to compute embeddings and similarity\n",
    "def Translation_assessment_1(df_1a_testing_output):\n",
    "    df_1a_testing_output['Question'] = df_1a_testing_output['Question'].fillna('').astype(str)\n",
    "    df_1a_testing_output['Translation'] = df_1a_testing_output['Translation'].fillna('').astype(str)\n",
    "    \n",
    "    # Generate embeddings for the \"Question\" and \"Translation\" columns\n",
    "    question_embeddings = embedding_model_1.encode(df_1a_testing_output['Question'].tolist(), task=\"text-matching\", convert_to_tensor=True)\n",
    "    translation_embeddings = embedding_model_1.encode(df_1a_testing_output['Translation'].tolist(), task=\"text-matching\", convert_to_tensor=True)\n",
    "\n",
    "    # Calculate cosine similarity for each row\n",
    "    similarities = cosine_similarity(question_embeddings, translation_embeddings)\n",
    "\n",
    "    # Since cosine_similarity returns a matrix, we extract the diagonal (row-wise comparison)\n",
    "    df_1a_testing_output['Similarity_1'] = np.diagonal(similarities)\n",
    "\n",
    "    return df_1a_testing_output\n",
    "\n",
    "# Call the function and process the dataframe\n",
    "df_translation_assessment_1 = Translation_assessment_1(df_1a_testing_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Version 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Specify preferred dimensions\n",
    "dimensions = 512\n",
    "\n",
    "# 2. Load the model\n",
    "embedding_model_2 = SentenceTransformer(\"mixedbread-ai/mxbai-embed-large-v1\", truncate_dim=dimensions)  # https://huggingface.co/mixedbread-ai/mxbai-embed-large-v1\n",
    "\n",
    "# Function to generate a detailed instruction for the query\n",
    "def get_detailed_instruct(task_description: str, query: str) -> str:\n",
    "    return f'Instruct: {task_description}\\nQuery: {query}'\n",
    "\n",
    "# Function to compute embeddings and similarity\n",
    "def Translation_assessment_2(df_1a_testing_output):\n",
    "    # Define task instruction for the queries\n",
    "    task = 'Compare the question and translation to assess the quality of the translation.'\n",
    "\n",
    "    # Add instruction to the \"Question\" column\n",
    "    questions_with_instructions = [\n",
    "        get_detailed_instruct(task, question) for question in df_1a_testing_output['Question'].tolist()\n",
    "    ]\n",
    "\n",
    "    # Generate a list of documents to encode\n",
    "    docs = questions_with_instructions + df_1a_testing_output['Translation'].tolist()\n",
    "    \n",
    "    # 2. Encode\n",
    "    embeddings = embedding_model_2.encode(docs)\n",
    "\n",
    "    # Optional: Quantize the embeddings\n",
    "    binary_embeddings = quantize_embeddings(embeddings, precision=\"ubinary\")\n",
    "\n",
    "    # Calculate cosine similarity between the first half (questions) and the second half (translations)\n",
    "    question_embeddings = embeddings[:len(questions_with_instructions)]\n",
    "    translation_embeddings = embeddings[len(questions_with_instructions):]\n",
    "\n",
    "    # Calculate cosine similarity\n",
    "    similarities = cos_sim(question_embeddings, translation_embeddings)\n",
    "\n",
    "    # Since cos_sim returns a matrix, we extract the diagonal (row-wise comparison)\n",
    "    df_1a_testing_output['Similarity_V2'] = np.diagonal(similarities.cpu().numpy())\n",
    "\n",
    "    return df_1a_testing_output\n",
    "\n",
    "# Call the function and process the dataframe\n",
    "df_translation_assessment_2 = Translation_assessment_2(df_1a_testing_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Version 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pre-trained model for generating sentence embeddings\n",
    "embedding_model = SentenceTransformer(\"thenlper/gte-large\")\n",
    "\n",
    "# Function to compute embeddings and similarity\n",
    "def Translation_assessment_3(df_1a_testing_output):\n",
    "    # Generate embeddings for the \"Question\" and \"Translation\" columns\n",
    "    question_embeddings = embedding_model.encode(df_1a_testing_output['Question'].tolist(), convert_to_tensor=True)\n",
    "    translation_embeddings = embedding_model.encode(df_1a_testing_output['Translation'].tolist(), convert_to_tensor=True)\n",
    "\n",
    "    # Calculate cosine similarity for each row\n",
    "    similarities = cosine_similarity(question_embeddings, translation_embeddings)\n",
    "\n",
    "    # Since cosine_similarity returns a matrix, we extract the diagonal (row-wise comparison)\n",
    "    df_1a_testing_output['Similarity_V3'] = np.diagonal(similarities)\n",
    "\n",
    "    return df_1a_testing_output\n",
    "\n",
    "# Call the function and process the dataframe\n",
    "df_translation_assessment_3 = Translation_assessment_3(df_1a_testing_output)\n",
    "\n",
    "# Saving to CSV with the similarity score\n",
    "df_translation_assessment_3.to_csv('../8_Testing_Input_and_Output/Translation_assessment_1a.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mtgitenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
