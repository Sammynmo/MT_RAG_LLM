{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***App Testing run and generation of file with App Output***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On Google Colab, mounting Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing App 1a**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../../A_Apps/1a_Gemma_RAG_Schema.ipynb #adjust path as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to performance issues with Gemma on Google Colab, the Testing dataset was divided into three parts. They are loaded and run separately below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the dataset and transform to dataframe\n",
    "# Define the dataset path\n",
    "dataset_path = \"/content/drive/MyDrive/Colab.Notebooks/Gemma_Testing/Spider_Testing_Selection_1.csv\" #adjust path as needed\n",
    "print(\"Dataset Path:\", dataset_path)\n",
    "\n",
    "# Check if the file exists at the specified path\n",
    "if not os.path.isfile(dataset_path):\n",
    "    raise FileNotFoundError(f\"Unable to find the file at {dataset_path}\")\n",
    "\n",
    "# Load the dataset\n",
    "testing_1a_1 = load_dataset('csv', data_files=dataset_path)\n",
    "\n",
    "# Convert the dataset to a pandas dataframe\n",
    "df_1a_testing_1 = testing_1a_1[\"train\"].to_pandas()\n",
    "\n",
    "# Print a few rows to verify\n",
    "print(df_1a_testing_1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the dataset and transform to dataframe\n",
    "# Define the dataset path\n",
    "dataset_path = \"/content/drive/MyDrive/Colab.Notebooks/Gemma_Testing/Spider_Testing_Selection_2.csv\" #adjust path as needed\n",
    "print(\"Dataset Path:\", dataset_path)\n",
    "\n",
    "# Check if the file exists at the specified path\n",
    "if not os.path.isfile(dataset_path):\n",
    "    raise FileNotFoundError(f\"Unable to find the file at {dataset_path}\")\n",
    "\n",
    "# Load the dataset\n",
    "testing_1a_2 = load_dataset('csv', data_files=dataset_path)\n",
    "\n",
    "# Convert the dataset to a pandas dataframe\n",
    "df_1a_testing_2 = testing_1a_2[\"train\"].to_pandas()\n",
    "\n",
    "# Print a few rows to verify\n",
    "print(df_1a_testing_2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the dataset and transform to dataframe\n",
    "# Define the dataset path\n",
    "dataset_path = \"/content/drive/MyDrive/Colab.Notebooks/Gemma_Testing/Spider_Testing_Selection_3.csv\" #adjust path as needed\n",
    "print(\"Dataset Path:\", dataset_path)\n",
    "\n",
    "# Check if the file exists at the specified path\n",
    "if not os.path.isfile(dataset_path):\n",
    "    raise FileNotFoundError(f\"Unable to find the file at {dataset_path}\")\n",
    "\n",
    "# Load the dataset\n",
    "testing_1a_3 = load_dataset('csv', data_files=dataset_path)\n",
    "\n",
    "# Convert the dataset to a pandas dataframe\n",
    "df_1a_testing_3 = testing_1a_3[\"train\"].to_pandas()\n",
    "\n",
    "# Print a few rows to verify\n",
    "print(df_1a_testing_3.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to run the chain for each query\n",
    "def process_queries_schema_1(df_1a_testing_1):\n",
    "    # Create an empty list to store the results\n",
    "    output = []\n",
    "\n",
    "    for i, row in df_1a_testing_1.iterrows():\n",
    "        # Get the question from the dataframe\n",
    "        query = row[\"Query\"]\n",
    "\n",
    "        # Execute the chain with the current query\n",
    "        try:\n",
    "            result = process_query_schema(query)\n",
    "        except Exception as e:\n",
    "            result = f\"Error processing query {i}: {str(e)}\"\n",
    "\n",
    "        # Append the result to the list\n",
    "        output.append(result)\n",
    "\n",
    "    # Add the results to a new column in the dataframe\n",
    "    df_1a_testing_1[\"Output\"] = output\n",
    "\n",
    "    return df_1a_testing_1\n",
    "\n",
    "# Call the function and process the dataframe\n",
    "df_1a_testing_output_1 = process_queries_schema_1(df_1a_testing_1)\n",
    "\n",
    "# Now 'df_with_results' contains the original queries and their corresponding results\n",
    "print(df_1a_testing_output_1)\n",
    "df_1a_testing_output_1.to_csv(\"../8_Testing_Input_and_Output/App_Output_1a_1.csv\", index=False) #adjust path as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to run the chain for each query\n",
    "def process_queries_schema_2(df_1a_testing_2):\n",
    "    # Create an empty list to store the results\n",
    "    output = []\n",
    "\n",
    "    for i, row in df_1a_testing_2.iterrows():\n",
    "        # Get the query from the dataframe\n",
    "        query = row[\"Query\"]\n",
    "\n",
    "        # Execute the chain with the current query\n",
    "        try:\n",
    "            result = process_query_schema(query)\n",
    "        except Exception as e:\n",
    "            result = f\"Error processing query {i}: {str(e)}\"\n",
    "\n",
    "        # Append the result to the list\n",
    "        output.append(result)\n",
    "\n",
    "    # Add the results to a new column in the dataframe\n",
    "    df_1a_testing_2[\"Output\"] = output\n",
    "\n",
    "    return df_1a_testing_2\n",
    "\n",
    "# Call the function and process the dataframe\n",
    "df_1a_testing_output_2 = process_queries_schema_2(df_1a_testing_2)\n",
    "\n",
    "# Now 'df_with_results' contains the original queries and their corresponding results\n",
    "print(df_1a_testing_output_2)\n",
    "df_1a_testing_output_2.to_csv(\"../8_Testing_Input_and_Output/App_Output_1a_2.csv\", index=False) #adjust path as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to run the chain for each query\n",
    "def process_questions_schema_3(df_1a_testing_3):\n",
    "    # Create an empty list to store the results\n",
    "    output = []\n",
    "\n",
    "    for i, row in df_1a_testing_3.iterrows():\n",
    "        # Get the query from the dataframe\n",
    "        query = row[\"Query\"]\n",
    "\n",
    "        # Execute the chain with the current query\n",
    "        try:\n",
    "            result = process_query_schema(query)\n",
    "        except Exception as e:\n",
    "            result = f\"Error processing query {i}: {str(e)}\"\n",
    "\n",
    "        # Append the result to the list\n",
    "        output.append(result)\n",
    "\n",
    "    # Add the results to a new column in the dataframe\n",
    "    df_1a_testing_3[\"Output\"] = output\n",
    "\n",
    "    return df_1a_testing_3\n",
    "\n",
    "# Call the function and process the dataframe\n",
    "df_1a_testing_output_3 = process_questions_schema_3(df_1a_testing_3)\n",
    "\n",
    "# Now 'df_with_results' contains the original questions and their corresponding results\n",
    "print(df_1a_testing_output_3)\n",
    "df_1a_testing_output_3.to_csv(\"../8_Testing_Input_and_Output/App_Output_1a_3.csv\", index=False) #adjust path as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing App 2a**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../../A_Apps/2a_Gemma_RAG.ipynb #adjust path as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to performance issues with Gemma on Google Colab, the Testing dataset was divided into three parts. They are loaded and run separately below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the dataset and transform to dataframe\n",
    "# Define the dataset path\n",
    "dataset_path = \"/content/drive/MyDrive/Colab.Notebooks/Gemma_Testing/Spider_Testing_Selection_1.csv\" #adjust path as needed\n",
    "print(\"Dataset Path:\", dataset_path)\n",
    "\n",
    "# Check if the file exists at the specified path\n",
    "if not os.path.isfile(dataset_path):\n",
    "    raise FileNotFoundError(f\"Unable to find the file at {dataset_path}\")\n",
    "\n",
    "# Load the dataset\n",
    "testing_2a_1 = load_dataset('csv', data_files=dataset_path)\n",
    "\n",
    "# Convert the dataset to a pandas dataframe\n",
    "df_2a_testing_1 = testing_2a_1[\"train\"].to_pandas()\n",
    "\n",
    "# Print a few rows to verify\n",
    "print(df_2a_testing_1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the dataset and transform to dataframe\n",
    "# Define the dataset path\n",
    "dataset_path = \"/content/drive/MyDrive/Colab.Notebooks/Gemma_Testing/Spider_Testing_Selection_2.csv\" #adjust path as needed\n",
    "print(\"Dataset Path:\", dataset_path)\n",
    "\n",
    "# Check if the file exists at the specified path\n",
    "if not os.path.isfile(dataset_path):\n",
    "    raise FileNotFoundError(f\"Unable to find the file at {dataset_path}\")\n",
    "\n",
    "# Load the dataset\n",
    "testing_2a_2 = load_dataset('csv', data_files=dataset_path)\n",
    "\n",
    "# Convert the dataset to a pandas dataframe\n",
    "df_2a_testing_2 = testing_2a_2[\"train\"].to_pandas()\n",
    "\n",
    "# Print a few rows to verify\n",
    "print(df_2a_testing_2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the dataset and transform to dataframe\n",
    "# Define the dataset path\n",
    "dataset_path = \"/content/drive/MyDrive/Colab.Notebooks/Gemma_Testing/Spider_Testing_Selection_3.csv\" #adjust path as needed\n",
    "print(\"Dataset Path:\", dataset_path)\n",
    "\n",
    "# Check if the file exists at the specified path\n",
    "if not os.path.isfile(dataset_path):\n",
    "    raise FileNotFoundError(f\"Unable to find the file at {dataset_path}\")\n",
    "\n",
    "# Load the dataset\n",
    "testing_2a_3 = load_dataset('csv', data_files=dataset_path)\n",
    "\n",
    "# Convert the dataset to a pandas dataframe\n",
    "df_2a_testing_3 = testing_2a_3[\"train\"].to_pandas()\n",
    "\n",
    "# Print a few rows to verify\n",
    "print(df_2a_testing_3.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to run the chain for each query\n",
    "def process_queries_1(df_2a_testing_1):\n",
    "    # Create an empty list to store the results\n",
    "    output = []\n",
    "\n",
    "    for i, row in df_2a_testing_1.iterrows():\n",
    "        # Get the query from the dataframe\n",
    "        query = row[\"Query\"]\n",
    "\n",
    "        # Execute the chain with the current query\n",
    "        try:\n",
    "            result = process_query_RAG(query)\n",
    "        except Exception as e:\n",
    "            result = f\"Error processing query {i}: {str(e)}\"\n",
    "\n",
    "        # Append the result to the list\n",
    "        output.append(result)\n",
    "\n",
    "    # Add the results to a new column in the dataframe\n",
    "    df_2a_testing_1[\"Output\"] = output\n",
    "\n",
    "    return df_2a_testing_1\n",
    "\n",
    "# Call the function and process the dataframe\n",
    "df_2a_testing_output_1 = process_queries_1(df_2a_testing_1)\n",
    "\n",
    "# Now 'df_with_results' contains the original queries and their corresponding results\n",
    "print(df_2a_testing_output_1)\n",
    "df_2a_testing_output_1.to_csv(\"../8_Testing_Input_and_Output/App_Output_2a_1.csv\", index=False) #adjust path as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to run the chain for each query\n",
    "def process_queries_2(df_2a_testing_2):\n",
    "    # Create an empty list to store the results\n",
    "    output = []\n",
    "\n",
    "    for i, row in df_2a_testing_2.iterrows():\n",
    "        # Get the query from the dataframe\n",
    "        query = row[\"Query\"]\n",
    "\n",
    "        # Execute the chain with the current query\n",
    "        try:\n",
    "            result = process_query_RAG(query)\n",
    "        except Exception as e:\n",
    "            result = f\"Error processing query {i}: {str(e)}\"\n",
    "\n",
    "        # Append the result to the list\n",
    "        output.append(result)\n",
    "\n",
    "    # Add the results to a new column in the dataframe\n",
    "    df_2a_testing_2[\"Output\"] = output\n",
    "\n",
    "    return df_2a_testing_2\n",
    "\n",
    "# Call the function and process the dataframe\n",
    "df_2a_testing_output_2 = process_queries_2(df_2a_testing_2)\n",
    "\n",
    "# Now 'df_with_results' contains the original queries and their corresponding results\n",
    "print(df_2a_testing_output_2)\n",
    "df_2a_testing_output_2.to_csv(\"../8_Testing_Input_and_Output/App_Output_2a_2.csv\", index=False) #adjust path as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to run the chain for each query\n",
    "def process_queries_3(df_2a_testing_3):\n",
    "    # Create an empty list to store the results\n",
    "    output = []\n",
    "\n",
    "    for i, row in df_2a_testing_3.iterrows():\n",
    "        # Get the query from the dataframe\n",
    "        query = row[\"Query\"]\n",
    "\n",
    "        # Execute the chain with the current query\n",
    "        try:\n",
    "            result = process_query_RAG(query)\n",
    "        except Exception as e:\n",
    "            result = f\"Error processing query {i}: {str(e)}\"\n",
    "\n",
    "        # Append the result to the list\n",
    "        output.append(result)\n",
    "\n",
    "    # Add the results to a new column in the dataframe\n",
    "    df_2a_testing_3[\"Output\"] = output\n",
    "\n",
    "    return df_2a_testing_3\n",
    "\n",
    "# Call the function and process the dataframe\n",
    "df_2a_testing_output_3 = process_queries_3(df_2a_testing_3)\n",
    "\n",
    "# Now 'df_with_results' contains the original queries and their corresponding results\n",
    "print(df_2a_testing_output_3)\n",
    "df_2a_testing_output_3.to_csv(\"../8_Testing_Input_and_Output/App_Output_2a_3.csv\", index=False) #adjust path as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing App 3a**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../../A_Apps/3a_Gemma.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to performance issues with Gemma on Google Colab, the Testing dataset was divided into three parts. They are loaded and run separately below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the dataset and transform to dataframe\n",
    "# Define the dataset path\n",
    "dataset_path = \"/content/drive/MyDrive/Colab.Notebooks/Gemma_Testing/Spider_Testing_Selection_1.csv\" #adjust path as needed\n",
    "print(\"Dataset Path:\", dataset_path)\n",
    "\n",
    "# Check if the file exists at the specified path\n",
    "if not os.path.isfile(dataset_path):\n",
    "    raise FileNotFoundError(f\"Unable to find the file at {dataset_path}\")\n",
    "\n",
    "# Load the dataset\n",
    "testing_3a_1 = load_dataset('csv', data_files=dataset_path)\n",
    "\n",
    "# Convert the dataset to a pandas dataframe\n",
    "df_3a_testing_1 = testing_3a_1[\"train\"].to_pandas()\n",
    "\n",
    "# Print a few rows to verify\n",
    "print(df_3a_testing_1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the dataset and transform to dataframe\n",
    "# Define the dataset path\n",
    "dataset_path = \"/content/drive/MyDrive/Colab.Notebooks/Gemma_Testing/Spider_Testing_Selection_2.csv\" #adjust path as needed\n",
    "print(\"Dataset Path:\", dataset_path)\n",
    "\n",
    "# Check if the file exists at the specified path\n",
    "if not os.path.isfile(dataset_path):\n",
    "    raise FileNotFoundError(f\"Unable to find the file at {dataset_path}\")\n",
    "\n",
    "# Load the dataset\n",
    "testing_3a_2 = load_dataset('csv', data_files=dataset_path)\n",
    "\n",
    "# Convert the dataset to a pandas dataframe\n",
    "df_3a_testing_2 = testing_3a_2[\"train\"].to_pandas()\n",
    "\n",
    "# Print a few rows to verify\n",
    "print(df_3a_testing_2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the dataset and transform to dataframe\n",
    "# Define the dataset path\n",
    "dataset_path = \"/content/drive/MyDrive/Colab.Notebooks/Gemma_Testing/Spider_Testing_Selection_3.csv\" #adjust path as needed\n",
    "print(\"Dataset Path:\", dataset_path)\n",
    "\n",
    "# Check if the file exists at the specified path\n",
    "if not os.path.isfile(dataset_path):\n",
    "    raise FileNotFoundError(f\"Unable to find the file at {dataset_path}\")\n",
    "\n",
    "# Load the dataset\n",
    "testing_3a_3 = load_dataset('csv', data_files=dataset_path)\n",
    "\n",
    "# Convert the dataset to a pandas dataframe\n",
    "df_3a_testing_3 = testing_3a_3[\"train\"].to_pandas()\n",
    "\n",
    "# Print a few rows to verify\n",
    "print(df_3a_testing_3.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to run the chain for each query\n",
    "def process_queries_1(df_3a_testing_1):\n",
    "    # Create an empty list to store the results\n",
    "    output = []\n",
    "\n",
    "    for i, row in df_3a_testing_1.iterrows():\n",
    "        # Get the query from the dataframe\n",
    "        query = row[\"Query\"]\n",
    "\n",
    "        # Execute the chain with the current query\n",
    "        try:\n",
    "            result = process_query(query)\n",
    "        except Exception as e:\n",
    "            result = f\"Error processing query {i}: {str(e)}\"\n",
    "\n",
    "        # Append the result to the list\n",
    "        output.append(result)\n",
    "\n",
    "    # Add the results to a new column in the dataframe\n",
    "    df_3a_testing_1[\"Output\"] = output\n",
    "\n",
    "    return df_3a_testing_1\n",
    "\n",
    "# Call the function and process the dataframe\n",
    "df_3a_testing_output_1 = process_queries_1(df_3a_testing_1)\n",
    "\n",
    "# Now 'df_with_results' contains the original queries and their corresponding results\n",
    "print(df_3a_testing_output_1)\n",
    "df_3a_testing_output_1.to_csv(\"../8_Testing_Input_and_Output/App_Output_3a_1.csv\", index=False) #adjust path as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to run the chain for each query\n",
    "def process_queries_2(df_3a_testing_2):\n",
    "    # Create an empty list to store the results\n",
    "    output = []\n",
    "\n",
    "    for i, row in df_3a_testing_2.iterrows():\n",
    "        # Get the query from the dataframe\n",
    "        query = row[\"Query\"]\n",
    "\n",
    "        # Execute the chain with the current query\n",
    "        try:\n",
    "            result = process_query(query)\n",
    "        except Exception as e:\n",
    "            result = f\"Error processing query {i}: {str(e)}\"\n",
    "\n",
    "        # Append the result to the list\n",
    "        output.append(result)\n",
    "\n",
    "    # Add the results to a new column in the dataframe\n",
    "    df_3a_testing_2[\"Output\"] = output\n",
    "\n",
    "    return df_3a_testing_2\n",
    "\n",
    "# Call the function and process the dataframe\n",
    "df_3a_testing_output_2 = process_queries_2(df_3a_testing_2)\n",
    "\n",
    "# Now 'df_with_results' contains the original queries and their corresponding results\n",
    "print(df_3a_testing_output_2)\n",
    "df_3a_testing_output_2.to_csv(\"../8_Testing_Input_and_Output/App_Output_3a_2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to run the chain for each query\n",
    "def process_queries_3(df_3a_testing_3):\n",
    "    # Create an empty list to store the results\n",
    "    output = []\n",
    "\n",
    "    for i, row in df_3a_testing_3.iterrows():\n",
    "        # Get the query from the dataframe\n",
    "        query = row[\"Query\"]\n",
    "\n",
    "        # Execute the chain with the current query\n",
    "        try:\n",
    "            result = process_query(query)\n",
    "        except Exception as e:\n",
    "            result = f\"Error processing query {i}: {str(e)}\"\n",
    "\n",
    "        # Append the result to the list\n",
    "        output.append(result)\n",
    "\n",
    "    # Add the results to a new column in the dataframe\n",
    "    df_3a_testing_3[\"Output\"] = output\n",
    "\n",
    "    return df_3a_testing_3\n",
    "\n",
    "# Call the function and process the dataframe\n",
    "df_3a_testing_output_3 = process_queries_1(df_3a_testing_3)\n",
    "\n",
    "# Now 'df_with_results' contains the original queries and their corresponding results\n",
    "print(df_3a_testing_output_3)\n",
    "df_3a_testing_output_3.to_csv(\"../8_Testing_Input_and_Output/App_Output_3a_3.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mtgitenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
