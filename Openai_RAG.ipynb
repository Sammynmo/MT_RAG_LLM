{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OPENAI RAG LLM setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\samir\\mtenv\\lib\\site-packages (0.2.14)\n",
      "Requirement already satisfied: pymongo in c:\\users\\samir\\mtenv\\lib\\site-packages (4.8.0)\n",
      "Requirement already satisfied: openai in c:\\users\\samir\\mtenv\\lib\\site-packages (1.40.8)\n",
      "Requirement already satisfied: gradio in c:\\users\\samir\\mtenv\\lib\\site-packages (4.41.0)\n",
      "Requirement already satisfied: requests in c:\\users\\samir\\mtenv\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: langchain_community in c:\\users\\samir\\mtenv\\lib\\site-packages (0.2.12)\n",
      "Requirement already satisfied: langchain-openai in c:\\users\\samir\\mtenv\\lib\\site-packages (0.1.21)\n",
      "Requirement already satisfied: langchain-mongodb in c:\\users\\samir\\mtenv\\lib\\site-packages (0.1.8)\n",
      "Requirement already satisfied: sentence_transformers in c:\\users\\samir\\mtenv\\lib\\site-packages (3.0.1)\n",
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\samir\\mtenv\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\samir\\mtenv\\lib\\site-packages (from langchain) (2.0.32)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\samir\\mtenv\\lib\\site-packages (from langchain) (3.10.3)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.32 in c:\\users\\samir\\mtenv\\lib\\site-packages (from langchain) (0.2.32)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in c:\\users\\samir\\mtenv\\lib\\site-packages (from langchain) (0.2.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\samir\\mtenv\\lib\\site-packages (from langchain) (0.1.99)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in c:\\users\\samir\\mtenv\\lib\\site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\samir\\mtenv\\lib\\site-packages (from langchain) (2.8.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\samir\\mtenv\\lib\\site-packages (from langchain) (8.5.0)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in c:\\users\\samir\\mtenv\\lib\\site-packages (from pymongo) (2.6.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\samir\\mtenv\\lib\\site-packages (from openai) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\samir\\mtenv\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\samir\\mtenv\\lib\\site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\samir\\mtenv\\lib\\site-packages (from openai) (0.5.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\samir\\mtenv\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\samir\\mtenv\\lib\\site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\samir\\mtenv\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in c:\\users\\samir\\mtenv\\lib\\site-packages (from gradio) (23.2.1)\n",
      "Requirement already satisfied: fastapi in c:\\users\\samir\\mtenv\\lib\\site-packages (from gradio) (0.112.1)\n",
      "Requirement already satisfied: ffmpy in c:\\users\\samir\\mtenv\\lib\\site-packages (from gradio) (0.4.0)\n",
      "Requirement already satisfied: gradio-client==1.3.0 in c:\\users\\samir\\mtenv\\lib\\site-packages (from gradio) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.3 in c:\\users\\samir\\mtenv\\lib\\site-packages (from gradio) (0.24.5)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in c:\\users\\samir\\mtenv\\lib\\site-packages (from gradio) (6.4.2)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\samir\\mtenv\\lib\\site-packages (from gradio) (3.1.4)\n",
      "Requirement already satisfied: markupsafe~=2.0 in c:\\users\\samir\\mtenv\\lib\\site-packages (from gradio) (2.1.5)\n",
      "Requirement already satisfied: matplotlib~=3.0 in c:\\users\\samir\\mtenv\\lib\\site-packages (from gradio) (3.9.2)\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\users\\samir\\mtenv\\lib\\site-packages (from gradio) (3.10.7)\n",
      "Requirement already satisfied: packaging in c:\\users\\samir\\mtenv\\lib\\site-packages (from gradio) (24.1)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\samir\\mtenv\\lib\\site-packages (from gradio) (2.2.2)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in c:\\users\\samir\\mtenv\\lib\\site-packages (from gradio) (10.4.0)\n",
      "Requirement already satisfied: pydub in c:\\users\\samir\\mtenv\\lib\\site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in c:\\users\\samir\\mtenv\\lib\\site-packages (from gradio) (0.0.9)\n",
      "Requirement already satisfied: ruff>=0.2.2 in c:\\users\\samir\\mtenv\\lib\\site-packages (from gradio) (0.6.0)\n",
      "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\samir\\mtenv\\lib\\site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: tomlkit==0.12.0 in c:\\users\\samir\\mtenv\\lib\\site-packages (from gradio) (0.12.0)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in c:\\users\\samir\\mtenv\\lib\\site-packages (from gradio) (0.12.3)\n",
      "Requirement already satisfied: urllib3~=2.0 in c:\\users\\samir\\mtenv\\lib\\site-packages (from gradio) (2.2.2)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\samir\\mtenv\\lib\\site-packages (from gradio) (0.30.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\samir\\mtenv\\lib\\site-packages (from gradio-client==1.3.0->gradio) (2024.6.1)\n",
      "Requirement already satisfied: websockets<13.0,>=10.0 in c:\\users\\samir\\mtenv\\lib\\site-packages (from gradio-client==1.3.0->gradio) (12.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\samir\\mtenv\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\samir\\mtenv\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\samir\\mtenv\\lib\\site-packages (from requests) (2024.7.4)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\samir\\mtenv\\lib\\site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in c:\\users\\samir\\mtenv\\lib\\site-packages (from langchain-openai) (0.7.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in c:\\users\\samir\\mtenv\\lib\\site-packages (from sentence_transformers) (4.44.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\samir\\mtenv\\lib\\site-packages (from sentence_transformers) (2.4.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\samir\\mtenv\\lib\\site-packages (from sentence_transformers) (1.5.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\samir\\mtenv\\lib\\site-packages (from sentence_transformers) (1.14.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\samir\\mtenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.3.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\samir\\mtenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\samir\\mtenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\samir\\mtenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\samir\\mtenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\samir\\mtenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\samir\\mtenv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.21.3)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\samir\\mtenv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\samir\\mtenv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\samir\\mtenv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\samir\\mtenv\\lib\\site-packages (from huggingface-hub>=0.19.3->gradio) (3.15.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\samir\\mtenv\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.32->langchain) (1.33)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\samir\\mtenv\\lib\\site-packages (from matplotlib~=3.0->gradio) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\samir\\mtenv\\lib\\site-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\samir\\mtenv\\lib\\site-packages (from matplotlib~=3.0->gradio) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\samir\\mtenv\\lib\\site-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\samir\\mtenv\\lib\\site-packages (from matplotlib~=3.0->gradio) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\samir\\mtenv\\lib\\site-packages (from matplotlib~=3.0->gradio) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\samir\\mtenv\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\samir\\mtenv\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\samir\\mtenv\\lib\\site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\samir\\mtenv\\lib\\site-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\samir\\mtenv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\samir\\mtenv\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.7.24)\n",
      "Requirement already satisfied: sympy in c:\\users\\samir\\mtenv\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (1.13.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\samir\\mtenv\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (3.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\samir\\mtenv\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (72.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\samir\\mtenv\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\samir\\mtenv\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.4.4)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\samir\\mtenv\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.19.1)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\samir\\mtenv\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\samir\\mtenv\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\samir\\mtenv\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
      "Requirement already satisfied: starlette<0.39.0,>=0.37.2 in c:\\users\\samir\\mtenv\\lib\\site-packages (from fastapi->gradio) (0.38.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\samir\\mtenv\\lib\\site-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\samir\\mtenv\\lib\\site-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\samir\\mtenv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.32->langchain) (3.0.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\samir\\mtenv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\samir\\mtenv\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\samir\\mtenv\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\samir\\mtenv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\samir\\mtenv\\lib\\site-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\samir\\mtenv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Installing the required packages\n",
    "%pip install langchain pymongo openai gradio requests langchain_community langchain-openai langchain-mongodb sentence_transformers python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "from pymongo import MongoClient\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_mongodb import MongoDBAtlasVectorSearch\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain_openai import OpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "import gradio as gr\n",
    "from gradio.themes.base import Base\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "from sentence_transformers import SentenceTransformer # https://huggingface.co/thenlper/gte-large\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Accessing secrets***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In Google Colab, you can use the following code to access the secret\n",
    "#from google.colab import userdata\n",
    "#MONGO_URI = userdata.get('MONGO_URI')\n",
    "\n",
    "# In your local environment, you can use the following code to access the secret\n",
    "load_dotenv()\n",
    "MONGO_URI = os.getenv(\"MONGO_URI\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Generating the embedding***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MongoDB setup\n",
    "client = MongoClient(MONGO_URI)\n",
    "dbName = \"MTGemma\"\n",
    "collectionName = \"MTGemma\"\n",
    "collection = client[dbName][collectionName]\n",
    "index_name = \"vector_index\"\n",
    "\n",
    "# Embedding model setup\n",
    "embedding_model = SentenceTransformer(\"thenlper/gte-large\")\n",
    "\n",
    "class CustomEmbeddingFunction:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def embed_documents(self, texts): # --> is this needed for this use case?\n",
    "        \"\"\"Embeds a list of documents.\"\"\"\n",
    "        embeddings = self.model.encode(texts)\n",
    "        return embeddings.tolist()\n",
    "\n",
    "    def embed_query(self, text):\n",
    "        \"\"\"Embeds a single query.\"\"\"\n",
    "        embedding = self.model.encode(text)\n",
    "        return embedding.tolist()\n",
    "\n",
    "# Wrap the SentenceTransformer model\n",
    "embedding_function = CustomEmbeddingFunction(embedding_model)\n",
    "\n",
    "# Vector store setup\n",
    "vector_store = MongoDBAtlasVectorSearch(\n",
    "    client=client,\n",
    "    database=dbName,\n",
    "    collection=collection,\n",
    "    index_name=index_name,\n",
    "    embedding=embedding_function,\n",
    "    text_key=\"Query\"  \n",
    ")\n",
    "\n",
    "# Retriever setup\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 4})\n",
    "\n",
    "# Define a custom logging retriever to see what the retriever is passing on\n",
    "class LoggingRetriever:\n",
    "    def __init__(self, retriever):\n",
    "        self.retriever = retriever\n",
    "\n",
    "    def __call__(self, query):\n",
    "        # Retrieve the documents\n",
    "        documents = self.retriever.invoke(query)\n",
    "        \n",
    "        # Log or print the retrieved documents\n",
    "        print(\"Retrieved Documents:\")\n",
    "        for doc in documents:\n",
    "            print(doc)\n",
    "        \n",
    "        # Return the retrieved documents\n",
    "        return documents\n",
    "\n",
    "# Wrap your retriever with the logging retriever\n",
    "logging_retriever = LoggingRetriever(retriever)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Chain setup***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved Documents:\n",
      "page_content='SELECT t1.name FROM stadium AS t1 JOIN event AS t2 ON t1.id  =  t2.stadium_id GROUP BY t2.stadium_id ORDER BY count(*) DESC LIMIT 1' metadata={'_id': '66b60159361489e02771bd8d', 'Question': 'What is the name of the stadium which held the most events?'}\n",
      "page_content='SELECT t3.name FROM record AS t1 JOIN event AS t2 ON t1.event_id  =  t2.id JOIN stadium AS t3 ON t3.id  =  t2.stadium_id GROUP BY t2.stadium_id ORDER BY count(*) DESC LIMIT 1' metadata={'_id': '66b60159361489e02771bd96', 'Question': 'Find the names of stadiums that the most swimmers have been to.'}\n",
      "page_content='SELECT T2.lastname FROM Performance AS T1 JOIN Band AS T2 ON T1.bandmate  =  T2.id WHERE stageposition  =  \"back\" GROUP BY lastname ORDER BY count(*) DESC LIMIT 1' metadata={'_id': '66b60159361489e02771bbe7', 'Question': 'What is the last name of the musician that has been at the back position the most?'}\n",
      "page_content='SELECT T2.lastname FROM Performance AS T1 JOIN Band AS T2 ON T1.bandmate  =  T2.id WHERE stageposition  =  \"back\" GROUP BY lastname ORDER BY count(*) DESC LIMIT 1' metadata={'_id': '66b60159361489e02771bbe8', 'Question': 'What is the last name of the musicians who has played back position the most?'}\n",
      "Prompt:\n",
      "input_variables=['context', 'question'] messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], template='\\nProvide a natural language translation and explanation of the SQL statement. Go through it step by step and use the information of the Context as examples. If you can\\'t answer the question, reply \"I don\\'t know\".\\n\\nContext: {context}\\n\\nQuestion: {question}\\n'))]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved Documents:\n",
      "page_content='SELECT t1.name FROM stadium AS t1 JOIN event AS t2 ON t1.id  =  t2.stadium_id GROUP BY t2.stadium_id ORDER BY count(*) DESC LIMIT 1' metadata={'_id': '66b60159361489e02771bd8d', 'Question': 'What is the name of the stadium which held the most events?'}\n",
      "page_content='SELECT t3.name FROM record AS t1 JOIN event AS t2 ON t1.event_id  =  t2.id JOIN stadium AS t3 ON t3.id  =  t2.stadium_id GROUP BY t2.stadium_id ORDER BY count(*) DESC LIMIT 1' metadata={'_id': '66b60159361489e02771bd96', 'Question': 'Find the names of stadiums that the most swimmers have been to.'}\n",
      "page_content='SELECT T2.lastname FROM Performance AS T1 JOIN Band AS T2 ON T1.bandmate  =  T2.id WHERE stageposition  =  \"back\" GROUP BY lastname ORDER BY count(*) DESC LIMIT 1' metadata={'_id': '66b60159361489e02771bbe7', 'Question': 'What is the last name of the musician that has been at the back position the most?'}\n",
      "page_content='SELECT T2.lastname FROM Performance AS T1 JOIN Band AS T2 ON T1.bandmate  =  T2.id WHERE stageposition  =  \"back\" GROUP BY lastname ORDER BY count(*) DESC LIMIT 1' metadata={'_id': '66b60159361489e02771bbe8', 'Question': 'What is the last name of the musicians who has played back position the most?'}\n"
     ]
    }
   ],
   "source": [
    "# Model and parsing setup\n",
    "model = ChatOpenAI(api_key=OPENAI_API_KEY, model=\"gpt-3.5-turbo\")\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# Define prompt template\n",
    "template = \"\"\"\n",
    "Provide a natural language translation and explanation of the SQL statement. Go through it step by step and use the information of the Context as examples. If you can't answer the question, reply \"I don't know\".\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# Chain setup\n",
    "chain = (\n",
    "    {\"context\": logging_retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | parser\n",
    ")\n",
    "\n",
    "# Execute the chain with the logging retriever\n",
    "chain.invoke(\"SELECT T2.name ,  T2.capacity FROM concert AS T1 JOIN stadium AS T2 ON T1.stadium_id  =  T2.stadium_id WHERE T1.year  >=  2014 GROUP BY T2.stadium_id ORDER BY count(*) DESC LIMIT 1?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Chat interface setup***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved Documents:\n",
      "page_content='SELECT t1.name FROM stadium AS t1 JOIN event AS t2 ON t1.id  =  t2.stadium_id GROUP BY t2.stadium_id ORDER BY count(*) DESC LIMIT 1' metadata={'_id': '66b60159361489e02771bd8d', 'Question': 'What is the name of the stadium which held the most events?'}\n",
      "page_content='SELECT t3.name FROM record AS t1 JOIN event AS t2 ON t1.event_id  =  t2.id JOIN stadium AS t3 ON t3.id  =  t2.stadium_id GROUP BY t2.stadium_id ORDER BY count(*) DESC LIMIT 1' metadata={'_id': '66b60159361489e02771bd96', 'Question': 'Find the names of stadiums that the most swimmers have been to.'}\n",
      "page_content='SELECT T2.lastname FROM Performance AS T1 JOIN Band AS T2 ON T1.bandmate  =  T2.id WHERE stageposition  =  \"back\" GROUP BY lastname ORDER BY count(*) DESC LIMIT 1' metadata={'_id': '66b60159361489e02771bbe7', 'Question': 'What is the last name of the musician that has been at the back position the most?'}\n",
      "page_content='SELECT T2.lastname FROM Performance AS T1 JOIN Band AS T2 ON T1.bandmate  =  T2.id WHERE stageposition  =  \"back\" GROUP BY lastname ORDER BY count(*) DESC LIMIT 1' metadata={'_id': '66b60159361489e02771bbe8', 'Question': 'What is the last name of the musicians who has played back position the most?'}\n"
     ]
    }
   ],
   "source": [
    "# Define the chain_invoke function\n",
    "def chain_invoke(question):\n",
    "    # Execute the chain with the logging retriever\n",
    "    result = chain.invoke(question)\n",
    "    # Return the result \n",
    "    return result\n",
    "\n",
    "# Create a web interface for the app, using Gradio\n",
    "with gr.Blocks(theme=Base(), title=\"Question Answering App using Vector Search + RAG\") as demo:\n",
    "    gr.Markdown(\n",
    "        \"\"\"\n",
    "        # Question Answering App using Atlas Vector Search + RAG Architecture\n",
    "        \"\"\")\n",
    "    textbox = gr.Textbox(label=\"Enter your SQL statement:\")\n",
    "    with gr.Row():\n",
    "        button = gr.Button(\"Submit\", variant=\"primary\")\n",
    "    output = gr.Textbox(lines=1, max_lines=30, label=\"Natural language translation and explanation:\")\n",
    "\n",
    "# Call chain_invoke function upon clicking the Submit button\n",
    "    button.click(chain_invoke, textbox, outputs=output)\n",
    "\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mtenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
